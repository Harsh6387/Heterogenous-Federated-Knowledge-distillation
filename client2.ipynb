{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812b615-071f-430e-97b0-f094fad692d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.5%"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import flwr as fl\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define transformations for data normalization\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),               # Resize to 224x224\n",
    "    transforms.RandomCrop(224, padding=4),       # Random crop with padding\n",
    "    transforms.RandomHorizontalFlip(),           # Random horizontal flip\n",
    "    transforms.RandomRotation(15),               # Random rotation in the range [-15, 15] degrees\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  # Random changes in brightness, contrast, saturation, and hue\n",
    "    transforms.RandomGrayscale(p=0.1),           # Convert to grayscale with a probability of 10%\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformation (translation)\n",
    "      # Randomly erasing parts of an image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),     # Normalizing using CIFAR-100 mean and std\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),  # CIFAR-100 mean and std\n",
    "])\n",
    "\n",
    "# Load ImageNet dataset\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "num_examples = {\"trainset\" : len(train_dataset), \"testset\" : len(test_dataset)}\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "\n",
    "# Set device (GPU or CPU)\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained ResNet-50 model\n",
    "net = models.vgg19(pretrained=False)  # Set pretrained=True to use pre-trained weights\n",
    "net.classifier[6] = torch.nn.Linear(in_features=4096, out_features=100)  # Adjust final layer for CIFAR-100 classes\n",
    "\n",
    "# Move the model to the specified device\n",
    "\n",
    "# Move the model to the device (GPU or CPU)\n",
    "net = net.to(device)\n",
    "# Print model summary\n",
    "print(net)\n",
    "def train(net, train_loader, epochs):\n",
    "    \"\"\"Train the model on the training set.\"\"\"\n",
    "    net.to(device)  # Move model to GPU if available\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=1e-4, weight_decay=1e-5)  # Using SGD for better results\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)  # Cosine Annealing LR scheduler\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = net(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_train_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "        # Adjust the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "def test(net, test_loader):\n",
    "    \"\"\"Validate the model on the test set.\"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "    net.eval()  # Set model to evaluation mode\n",
    "    criterion = nn.CrossEntropyLoss().to(device)  # Ensure criterion is on the same device\n",
    "    correct, total = 0, 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()  # Sum the loss for averaging later\n",
    "\n",
    "            # Get predictions and calculate correct predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)  # Total number of labels\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = running_loss / len(test_loader)  # Average loss over all batches\n",
    "    accuracy = 100. * correct / total  # Correct predictions percentage\n",
    "\n",
    "    print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "class CifarClient(fl.client.NumPyClient):\n",
    "    \n",
    "    def get_parameters(self, config):\n",
    "        return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        train(net, train_loader, epochs=15)\n",
    "        return self.get_parameters(config={}), num_examples[\"trainset\"], {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss, accuracy = test(net, test_loader)\n",
    "        return float(loss), num_examples[\"testset\"], {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "\n",
    "fl.client.start_numpy_client(server_address=\"127.0.0.1:8082\", client=CifarClient(),)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
